<html>
<head>
    <title>Projects</title>
    <meta name="url" content="projects" />
    <meta name="save_as" content="projects.html" />
    <meta name="show_in_top_menu" content="true" />
    <meta name="order" content="1" />
    <meta name="top_menu_name" content="Projects" />
    <meta name="show_as_selected" content="projects" />
    <meta name="table_of_contents" content="true" />
    <meta name="description" content="CON projects - Open source projects to facilitate efficient, scalable and reproducible research" />
    <meta name="author" content="CON" />
</head>
<body>
  <h1 style="margin-top:20px">Software</h1>

  <div class="row">
	<h2 id="datalad">DataLad</h2>
	<figure>
      <a href="https://datalad.org">
		<img src="/theme/img/3rd/datalad_logo.png" alt="DataLad" class="pull-right" style="width:255px;padding-left:5px;margin-top:-2em;" /></a>
    </figure>
	<p>
	  <a href="https://datalad.org">DataLad</a> is ongoing work funded
	  by NSF and German BMBF, to adapt the model of open-source
	  software (OSS) distributions to address the technical
	  limitations of today's data-sharing and provides a versatile
	  data management platform.  It uses software for data tracking and
	  deployment logistics specialized for large data
	  (<a class="reference external" href="http://git-annex.branchable.com">git-annex</a>) built
	  atop <a class="reference external" href="http://git-scm.com">Git</a>, the most capable distributed
	  version control system (dVCS) available today. DataLad provides
	  access to data available from various sources (e.g. lab or
	  consortium web-sites such as <a class="reference external"
	  href="http://humanconnectome.org">humanconnectome.org</a>;
	  data sharing portals such as <a class="reference external" href="http://openneuro.org">openneuro.org</a>
	  and <a class="reference external" href="http://crcns.org">crcns.org</a>) through a single
	  interface. It enables students and scientists to operate on data
	  using familiar concepts, such as files and directories, while
	  transparently managing data access and authorization with underlying
	  hosting providers.
	</p>
	<ul>
	  <li>
		  <a href="/whoweare#michael_hanke_" class="centroid">M. Hanke</a>,
		  <a href="/whoweare#matteo_visconti_di_oleggio_castello_" class="centroid">M. Visconti di Oleggio Castello</a>,
		  <a href="/whoweare#kyle_meyer_" class="centroid">K. Meyer</a>,
		  <a href="/whoweare#benjamin_poldrack_" class="centroid">B. Poldrack</a>,
		  and
		  <a href="/whoweare#yaroslav_o_halchenko_" class="centroid">Y.O. Halchenko</a>
		  (2018). <a href="https://github.com/myyoda/poster/blob/master/ohbm2018.pdf">YODA: YODA's organigram on data
			analysis.</a> OHBM 2018, Singapore.
	  </li>
	  <li>
		<a href="https://doi.org/10.21105/joss.03262">JOSS
		paper</a>: providing a succinct overview of
		DataLad
	  </li>
	  <li>
		<a href="http://handbook.datalad.org">DataLad Handbook</a>:
		everything you need to know about DataLad.
	  </li>
	  <li> <a href="https://www.datalad.org/#supporting-datalad">Funding support</a> </li>
	</ul>

  </div>

    <div class="row">
	<h2 id="dandi">DANDI</h2>
	<figure>
      <a href="https://dandiarchive.org"><img src="/theme/img/3rd/dandi_logo.png" alt="DANDI" class="pull-left" style="width:155px;padding-right:5px;margin-top:0em;" /></a>
    </figure>
	<p>
	  <a href="https://dandiarchive.org">Distributed Archives for
	  Neurophysiology Data Integration (DANDI)</a> is a platform for
	  publishing, sharing, and processing neurophysiology data funded
	  by the <a href="https://braininitiative.nih.gov/">BRAIN
	  Initiative</a>. The platform is now available for data upload
	  and distribution, and provides supplementary client tools to
	  assist with introspection and organization of data
	  following <a href="#nwb">NWB standard</a>.
	</p>
	<ul>
	  <li>
		<a href="https://projectreporter.nih.gov/project_info_description.cfm?aid=9795271">NIH (#1R24MH117295-01A1)</a>. PIs:
		<a href="https://mcgovern.mit.edu/profile/satrajit-ghosh/" class="centroid">S. Ghosh</a>
		and
 		<a href="/whoweare#yaroslav_o_halchenko_" class="centroid">Y.O. Halchenko</a>
	  </li>
	</ul>

  </div>

  <div class="row">
    <h2 id="datalad-registry">DataLad-Registry</h2>
    <figure>
      <a href="https://registry.datalad.org">
        <img src="/theme/img/3rd/registry_logo.svg" alt="DataLad-Registry"
             class="pull-right"
             style="height:4.4em;padding-left:1em;margin-top:-0.3em;"/></a>
    </figure>
    <p>
      <a href="https://registry.datalad.org">DataLad-Registry</a> is a service that
      maintains up-to-date information on an expanding collection of datasets, currently
      numbering over ten thousand. It automatically registers datasets from various
      online sources, extracts metadata, and keeps both the datasets and their metadata
      current. DataLad-Registry offers search functionalities, including metadata-based
      searches, accessible through both a web interface and a RESTful API.
    </p>
    <ul>
      <li style="cursor: pointer">
        <details>
          <summary>
            Talk at distribits 2024: Bringing Benefits of Centrality to Datalad (click to expand)
          </summary>

          <iframe width="560" height="315"
                  src="https://www.youtube.com/embed/_McJ1BtLsiQ?si=OTtLO8QFwzEL1Qiv"
                  title="YouTube video player"
                  allow="accelerometer; autoplay; clipboard-write; encrypted-media; fullscreen; gyroscope; picture-in-picture; web-share"
                  referrerpolicy="strict-origin-when-cross-origin"
                  style="border-width: 0"></iframe>
        </details>
      </li>
    </ul>
  </div>

  <div class="row">
	<h2>DueCredit</h2>
	<figure>
      <a href="https://datalad.org"><img src="/theme/img/3rd/duecredit_logo.png" alt="DueCredit" class="pull-left" style="width:155px;padding-right:10px;margin-top:0em;" /></a>
    </figure>
	<p>
	  <a href="https://github.com/duecredit/duecredit">DueCredit</a>
	  provides solution for the problem of inadequate citation and
	  referencing of scientific software and methods.  It provides a
	  simple framework (at the moment for Python only) to embed
	  publication or other references in the original code so they are
	  automatically collected and reported to the user at the
	  necessary level of reference detail, i.e. only references for
	  actually used functionality will be presented back if software
	  provides multiple citeable implementations.
	</p>
	<p>
	  As a side-effect, we hope that DueCredit also will reduce demand
	  in "prima-ballerina" projects, will encourage contributions to
	  existing open-source codebases, and as a result would solidify
	  scientific software ecosystem.
	</p>
	<ul>
	  <li>
		<a href="/whoweare#yaroslav_o_halchenko_" class="centroid">Y.O. Halchenko</a>
		and
		<a href="/whoweare#matteo_visconti_di_oleggio_castello_" class="centroid">M. Visconti di Oleggio Castello</a>
		(2016).
		<a href="http://haxbylab.dartmouth.edu/publications/HV+OHBM16.pdf">
		  DueCredit - automagically collect citations for software,
		  methods, and data you use.
		</a> OHBM 2016, Geneva, Switzerland
	  </li>
	</ul>
  </div>

  <div class="row">
	<h2>HeuDiConv / ReproIn</h2>
	<p>
	  <a href="https://github.com/nipy/heudiconv">HeuDiConv</a> is a
	  flexible DICOM converter for organizing brain imaging data into
	  structured directory layouts. As a part of the larger, NIH
	  supported <a href="http://repronim.org">ReproNim</a> effort, we
	  are developing a HeuDiConv-based <a href="http://reproin.repronim.org">ReproIn</a>
      solution for turnkey
	  automatic conversion of all collected MR data to a collection of
	  the BIDS DataLad datasets. It includes a flexible BIDS-like
	  specification how to name scanning sequences in the scanner, and
	  a <a href="https://github.com/nipy/heudiconv/blob/master/heudiconv/heuristics/reproin.py">HeuDiConv
	  reproin.py heuristic</a> to automate layout and conversion of
	  the datasets.  This solution is deployed
	  at <a href="https://www.dartmouth.edu/dbic/">DBIC (Dartmouth Brain
	  Imaging Center)</a>, it already facilitates reproducible
	  research, data sharing, and uploads to central archives such as
	  NDA.
	</p>
	<ul>
	  <li>
		Halchenko et al., (2024). HeuDiConv â€” flexible DICOM
		conversion into structured directory layouts. Journal of Open
		Source Software, 9(99), 5839
		<a href="https://joss.theoj.org/papers/10.21105/joss.05839">DOI: 10.21105/joss.05839</a>.
	  </li>
	  <li>
		<a href="/whoweare#matteo_visconti_di_oleggio_castello_" class="centroid">M. Visconti di Oleggio Castello</a>,
		James E. Dobson,
		Terry Sackett,
		Chandana Kodiweera,
		<a href="/whoweare#james_v_haxby_" class="centroid">J.V. Haxby</a>,
		M. Goncalves,
		S. Ghosh,
		<a href="/whoweare#yaroslav_o_halchenko_" class="centroid">Y.O. Halchenko</a>
		<a href="http://goo.gl/Z3soj7">ReproIn: automatic generation of shareable,
		  version-controlled BIDS datasets from MR scanners</a>,
		OHBM 2018, Singapore.
	  </li>
	</ul>
  </div>

  <div class="row">
	<h2 id="neurodebian">NeuroDebian</h2>
    <figure>
      <a href="https://neuro.debian.net"><img src="/theme/img/3rd/neurodebian_logo.jpg" alt="neurodebian" class="pull-right" style="padding-left:10px;margin-top:-2em;" /></a>
    </figure>
	<p>
	  <a href="https://neuro.debian.net">NeuroDebian</a> is a turnkey
	  research software platform for all aspects of the
	  neuroscientific research process. It takes the ideas of the
	  software hosting portals such
	  as <a href="http://nitrc.org">NITRC</a> on maximizing research
	  transparency and methods sharing, one step further, by providing
	  a comprehensive suite of readily usable and fully integrated
	  software with a robust testing and deployment
	  infrastructure. Consequently, it improves interoperability among
	  the tools and frees researchers from the burden of tedious
	  installation or upgrade procedures. That, in turn, positively
	  affects their availability for actual research activities, as
	  well as their motivation to test new analysis tools and stay
	  connected with the latest methodological developments in the
	  field.
	  </p>

	<ul>
	  <li>
	  <a href="/whoweare#yaroslav_o_halchenko_" class="centroid">Y.O. Halchenko</a>
	  &amp; <a href="/whoweare#michael_hanke_" class="centroid">M. Hanke</a> (2012).
	  <a href="https://www.frontiersin.org/articles/10.3389/fninf.2012.00022/full">
		Open is not enough. Let's take the next step: An integrated, community-driven computing platform for neuroscience.</a>
	  Frontiers in Neuroinformatics, 6:22.
	  <a href="http://haxbylab.dartmouth.edu/publications/HH12.pdf">[PDF]</a> DOI: 10.3389/fninf.2012.00022
	  </li>
	</ul>
  </div>

  <div class="row">
	<h2 id="pymvpa">PyMVPA</h2>
    <figure>
      <a href="http://pymvpa.org"><img src="/theme/img/3rd/pymvpa_logo.png" alt="PyMVPA" class="pull-left" style="width:395px;padding-right:10px;margin-top:0em;" /></a>
    </figure>
	<p>
	  <a href="http://www.pymvpa.org">PyMVPA</a> is a Python-based
	  framework for neural decoding using multivariate pattern
	  analysis.  It affords both volume- and surface-based analyses
	  using a wide variety of supervised and unsupervised machine
	  learning methods, representational similarity analyses,
	  searchlight analyses, hyperalignment of representational spaces,
	  and model-based decoding and encoding.  The software also can be
	  used for neural data other than fMRI, including analysis of MEG
	  and EEG data through spatio-temporo-frequency band searchlights
	  and cross-modal EEG to fMRI trans-fusion.  It also has been used
	  for analyses on data unrelated to neuroscience, demonstrating
	  its general utility.  PyMVPA also serves as a repository for
	  sample data sets (e.g., Haxby et al. 2001) that has found wide
	  applicability for education, development of new algorithms, or
	  new analyses and independent research reports.
	</p>

	<ul>
	  <li>
		<a href="/whoweare#michael_hanke_"
		   class="centroid">M. Hanke</a>,
		<a href="/whoweare#yaroslav_o_halchenko_" class="centroid">Y.O. Halchenko</a>, et al. (2009).
		<a href="http://link.springer.com/article/10.1007%2Fs12021-008-9041-y">PyMVPA: A Python toolbox for multivariate pattern analysis of fMRI data.</a>
		Neuroinformatics, 7, 37-53. DOI: 10.1007/s12021-008-9041-y
	  </li>
	</ul>
  </div>


  <div class="row">
	<h2>ReproMan</h2>
	<figure>
      <a href="http://reproman.repronim.org">
		<img src="/theme/img/3rd/niceman_logo.png" alt="NICEMAN"
			 class="pull-right"
			 style="width:155px;padding-left:5px;margin-top:-2em;" />
	  </a>
    </figure>

	<p>
	  <a href="https://github.com/repronim/niceman">ReproMan
	  (Reproducible computational environments Manager; formerly known
	  as REPROMAN)</a> is also a
	  part of the NIH
	  supported <a href="http://repronim.org">ReproNim</a> effort.  It
	  aims to facilitate reproducible computation via collection of
	  detailed information about origin of the used components (Debian
	  and/or Conda packages, VCS repositories, etc), so that
	  computational environments could be analyzed, and re-created.
	</p>
	<ul>
	  <li>
		M. Travers, R. Buccigrossi, C. Haselgrove,
		<a href="/whoweare#kyle_meyer_" class="centroid">K. Meyer</a>,
		and
		<a href="/whoweare#yaroslav_o_halchenko_" class="centroid">Y.O. Halchenko</a>
		<a href="http://goo.gl/CvaY1e">NICEMAN: NeuroImaging
		  Computational Environments Manager</a>, OHBM 2018, Singapore.
	  </li>
	</ul>
  </div>
  
  <div class="row">
	    <h2>con/duct</h2>
	    <figure>
          <a href="https://github.com/con/duct">
		          <img src="/theme/img/3rd/duct.webp" alt="con/duct"
			             class="pull-left"
			             style="width:255px;padding-right:10px;margin-top:0em;" />
	        </a>
      </figure>

	    <p>
	        <a href="https://github.com/con/duct">con/duct</a>
          (or just duct) is a lightweight wrapper that collects execution data for an
          arbitrary command.  Execution data includes execution time, system
          information, and resource usage statistics of the command and all its
          child processes.

          duct is intended to simplify the problem of recording the resources
          necessary to execute a command, particularly in an HPC environment.
          Additionally duct includes optional helpers that interact with
          logs produced by duct exectutions.
	    </p>
  </div>


  <div class="row">
	<h2 id="tinuous">(con/)tinuous</h2>
	<p>
	  <a href="https://github.com/con/tinuous/">tinuous</a> is a
	  command for downloading build logs and (for GitHub only)
	  artifacts and release assets for a GitHub repository from GitHub
	  Actions, Travis-CI.com, and/or Appveyor. By downloading them
	  all, and optionally placing them
	  under <a href="#datalad">DataLad</a> control you can establish
	  the backup, distribution, and convenient harmonious access to
	  all those artifacts.
	</p>
  </div>

  <div class="row">
	<h2 id="pyout">pyout</h2>
	<figure>
	  <a href="https://github.com/pyout/pyout">
		<img src="/theme/img/3rd/pyout_logo.png" alt="pyout"
			 class="pull-right"
			 style="width:155px;padding-left:5px;margin-top:-2em;" />
	  </a>
	</figure>
	<p>
	  <a href="https://github.com/pyout/pyout/">pyout</a> is a Python
	  package that defines an interface for writing structured records
	  as a table in a terminal. It is being developed to replace
	  custom code for displaying tabular data in
	  in <a href="#dandi">DANDI client</a> and others.
	</p>
  </div>


  <div class="row">
	    <h2>Quail</h2>
	    <figure>
          <a href="https://cdl-quail.readthedocs.io/en/latest/">
		          <img src="/theme/img/3rd/quail_logo.png" alt="Quail"
			             class="pull-left"
			             style="width:155px;margin-right:30px;margin-top:0.5em;" />
	        </a>
      </figure>

	    <p>
	        <a href="https://cdl-quail.readthedocs.io/en/latest/">Quail</a>
          is a Python toolbox for analyzing data from free recall memory experiments.  Some key features include:</p>
			<ul>
              <li> A simple data structure for storing encoding and recall data</li>
              <li> A set of functions for analyzing data by computing standard memory performance metrics</li>
              <li> A simple API for customizing plot styles</li>
              <li> Support for "naturalistic" stimuli such as movies, texts, and speech data</li>
              <li> A set of powerful tools for importing data, automatically transcribing audio files (speech-to-text), and more</li>
			</ul>
			<ul>
	        <li>A.C. Heusser, P.C. Fitzpatrick, C.E. Field, K. Ziman, and
	        <a href="/whoweare#jeremy_rothman_manning_" class="centroid">J.R. Manning</a>
	        (2017).
			<a href="http://joss.theoj.org/papers/3fb5123eb2538e06f6a25ded0a088b73">Quail: A Python toolbox for analyzing and plotting free recall data</a>.  The Journal of Open Source Software, 2(18): 424.</li>
	    </ul>
  </div>

  <div class="row">
	    <h2>HyperTools</h2>
	    <figure>
          <a href="https://hypertools.readthedocs.io/en/latest/">
		          <img src="/theme/img/3rd/hypertools_logo.png" alt="HyperTools"
			             class="pull-right"
			             style="width:155px;padding-left:5px;margin-top:-2em;" />
	        </a>
      </figure>

	    <p>
	        <a href="https://hypertools.readthedocs.io/en/latest/">HyperTools</a>
          is a Python toolbox for gaining geometric insights into high dimensional data.  Features include:
	    </p>
			<ul>
              <li>Functions for plotting high-dimensional datasets in 2D and 3D</li>
              <li>Static and animated plots</li>
              <li>Simple API for customizing plot styles</li>
              <li>Set of powerful data manipulation tools including hyperalignment, <i>k</i>-means clustering, normalizing, and more</li>
              <li>Support of lists of Numpy arrays, Pandas dataframes, text, or (mixed) lists</li>
              <li>Applying topic models and other text and word embedding methods to text data</li>
          </ul>
	    <ul>
	      <li>A.C. Heusser, K. Ziman, L.L.W. Owen, and
	        <a href="/whoweare#jeremy_rothman_manning_" class="centroid">J.R. Manning</a>
			(2018).  <a href="http://www.jmlr.org/papers/volume18/17-434/17-434.pdf">HyperTools: a Python Toolbox for Gaining Geometric Insights into High-Dimensional Data</a>.  Journal of Machine Learning Research, 18: 1-6.</li>
	    </ul>
  </div>

  <div class="row">
	    <h2>SuperEEG</h2>
	    <figure>
          <a href="https://supereeg.readthedocs.io/en/latest/">
		          <img src="/theme/img/3rd/supereeg_logo.png" alt="SuperEEG"
			             class="pull-left"
			             style="width:155px;padding-right:10px;margin-top:0em;" />
	        </a>
      </figure>

	    <p>
	        <a href="https://supereeg.readthedocs.io/en/latest/">SuperEEG</a>
          is a Python toolbox for inferring whole-brain activity from sparse
          ECoG recordings. The way the technique works is to leverage data from
          different patients' brains (who had electrodes implanted in different
          locations) to learn a "correlation model" that describes how activity
          patterns at different locations throughout the brain relate. Given
          this model, along with data from a sparse set of locations, we use
          Gaussian process regression to "fill in" what the patients' brains
          were "most probably" doing when those recordings were taken. Details
          on our approach may be found in <a href="https://www.biorxiv.org/content/early/2018/10/12/121020">this
          preprint</a>. You may also be
          interested in watching <a href="https://www.youtube.com/watch?v=t6snLszEneA&feature=youtu.be&t=35">this
          talk</a> or reading this <a href="https://community.sfn.org/t/supereeg-ecog-data-breaks-free-from-electrodes/8344">blog
          post</a> from a recent conference.
	    </p>
	    <ul>
	      <li>L.L.W. Owen, A.C. Heusser, and
			<a href="/whoweare#jeremy_rothman_manning_" class="centroid">J.R. Manning</a>
			(2018).  <a href="https://www.biorxiv.org/content/early/2018/10/12/121020">A
	            Gaussian process model of human electrocorticographic data</a>.  bioRxiv, 121020.</li>
	    </ul>
  </div>

  <h1>Initiatives</h1>
  <div class="row">
	<h2>Open Brain Consent</h2>
	<p>
	  <a href="http://open-brain-consent.readthedocs.org">Open Brain
	  Consent</a> initiative aims to facilitate neuroimaging data
	  sharing by providing an "out of the box" solution addressing
	  aforementioned human subjects concerns and consisting of
	</p>
	  <ul>
		<li>widely acceptable consent form allowing deposition of
		  anonymized data to public data archives</li>
		<li>collection of tools/pipelines to help anonymization of
		  neuroimaging data making it ready for sharing</li>
	  </ul>

	<ul>
	  <li>
		<a href="/whoweare#yaroslav_o_halchenko_" class="centroid">Y.O. Halchenko</a>,
		C.F. Gorgolewski, et al.
	  </li>
	</ul>
  </div>

  <!-- TODO Code review for Nature Neuroscience
https://www.nature.com/articles/nn.4579
https://www.nature.com/articles/nn.4550
 -->
  <!-- TODO: scicubator? -->

  <h1>Standards</h1>

  <div class="row">
	<h2 id="bids">Brain Imaging Data Structure (BIDS)</h2>
	<figure>
      <a href="http://bids.neuroimaging.io">
		<img src="/theme/img/3rd/bids_logo.png" alt="BIDS"
			 class="pull-right"
			 style="width:255px;padding-left:10px;margin-top:-2em;" />
	  </a>
    </figure>
	<p>
	  <a href="http://bids.neuroimaging.io">BIDS</a> is a
	  project lead by a steering group elected by the BIDS community
    to provide a simple and intuitive way to organize and describe your
	  neuroimaging and behavioral data.
	</p>
	<ul>
	  <li>
		Gorgolewski, K. J., et many,
		<a href="/whoweare#yaroslav_o_halchenko_" class="centroid">Y.O. Halchenko</a>
		et many more (2016).
		<a href="http://www.nature.com/articles/sdata201644">The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments.</a>
		Scientific Data, 3. DOI: 10.1038/sdata.2016.44
	  </li>
	  <li>
		<a href="https://github.com/bids-standard/bids-examples">Example (test)
		  datasets</a>
	  </li>
	  <li>
		<a href="http://datasets.datalad.org/?dir=/openfmri">Historical OpenfMRI</a> and up-to-date
		<a href="http://datasets.datalad.org/?dir=/openneuro">OpenNeuro</a>
		Datasets in DataLad distribution.
	  </li>
	</ul>
  </div>

  <div class="row">
	<h2 id="nwb">Neurodata Without Borders: Neurophysiology (NWB:N)</h2>
	<figure>
      <a href="https://www.nwb.org/">
		<img src="/theme/img/3rd/nwb_logo.png" alt="NWB"
			 class="pull-left"
			 style="width:255px;padding-right:10px;margin-top:0em;" />
	  </a>
    </figure>
	<p>
	  <a href="https://www.nwb.org/">NWB:N</a> is a data standard for
	  neurophysiology, providing neuroscientists with a common
	  standard to share, archive, use, and build analysis tools for
	  neurophysiology data. It is a standard supported
	  by <a href="#bids">BIDS</a> and the <a href="#dandi">DANDI
		archive</a>.
	</p>
  </div>

  <h1>Education</h1>
  <div class="row">
	<h2>ReproNim: Reproducible Basics</h2>
	<p>
	  <a href="http://www.reproducibleimaging.org/module-reproducible-basics">Reproducible
	  Basics</a> training module of the ReproNim training curriculum
	  presents daily core tools (shell, version control, etc) and
	  explains how you could make your research more reproducible
	  having gained improved knowledge of them.
	</p>
	<ul>
	  <li>
		<a href="/whoweare#yaroslav_o_halchenko_" class="centroid">Y.O. Halchenko</a>
		et al.
	  </li>
	</ul>
  </div>


  <h1>Infrastructure</h1>
  <div class="row">
	<h2>SingularityHub (after-life)</h2>
	<p>
	  To provide archival and uninterrupted access to over 9TBs of
	  singularity-hub.org Singularity containers, we have
	  established <a href="https://datasets.datalad.org/?dir=/shub">///shub DataLad dataset</a> and a service to serve all
	  the shub:// URLs.
	</p>
  </div>

</body>
</html>
